{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"cb6c1a2da064481896ee1a2909ab1241":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c60ad0eef64491c81e1fe7dd47576f9","IPY_MODEL_bf4b9eafd74f4fe09e4a3d0437ed2e55","IPY_MODEL_6d9990d94c0542e081de271476ac1547"],"layout":"IPY_MODEL_efa5d1d73163433390188f586845c9e4"}},"6c60ad0eef64491c81e1fe7dd47576f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37d8d3f5320c4c73891cac936f99d937","placeholder":"​","style":"IPY_MODEL_eaf9ffc0f663411e93be34277f8faa81","value":"Downloading builder script: 100%"}},"bf4b9eafd74f4fe09e4a3d0437ed2e55":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1489f790949e4033bee93e6801d772d9","max":6270,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20d983edde864d43aeb7e13382242343","value":6270}},"6d9990d94c0542e081de271476ac1547":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc5b4fa3973842b180ffe5a64efa0470","placeholder":"​","style":"IPY_MODEL_6f7f947ad7984ccf84dd9a0e680db084","value":" 6.27k/6.27k [00:00&lt;00:00, 219kB/s]"}},"efa5d1d73163433390188f586845c9e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37d8d3f5320c4c73891cac936f99d937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaf9ffc0f663411e93be34277f8faa81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1489f790949e4033bee93e6801d772d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20d983edde864d43aeb7e13382242343":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc5b4fa3973842b180ffe5a64efa0470":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f7f947ad7984ccf84dd9a0e680db084":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07a46c2a010f43fa805b303c9171324c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_527261a474854cb69542191dedc630be","IPY_MODEL_67ff8e6ef70f4d6196f214fc05e55c8f","IPY_MODEL_a22ce419758d48ba84fac5f9b686940e"],"layout":"IPY_MODEL_5df9eb7c3db24e4fbeb7097c3bcc20c5"}},"527261a474854cb69542191dedc630be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1da0a81f23ea4e609e01e0c0d5640929","placeholder":"​","style":"IPY_MODEL_8488e365c02c477986f0cd425912e556","value":"config.json: 100%"}},"67ff8e6ef70f4d6196f214fc05e55c8f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e28a8264652f45a8a4a9a9981d8ad081","max":1202,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dcf88215093947409800cd93ebb86072","value":1202}},"a22ce419758d48ba84fac5f9b686940e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b284a4c0a6184038872ebebed678f9ac","placeholder":"​","style":"IPY_MODEL_17c8d81f75de48e4ba71e639613f28f2","value":" 1.20k/1.20k [00:00&lt;00:00, 16.7kB/s]"}},"5df9eb7c3db24e4fbeb7097c3bcc20c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1da0a81f23ea4e609e01e0c0d5640929":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8488e365c02c477986f0cd425912e556":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e28a8264652f45a8a4a9a9981d8ad081":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcf88215093947409800cd93ebb86072":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b284a4c0a6184038872ebebed678f9ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17c8d81f75de48e4ba71e639613f28f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95c99d73edd64aeba72b9998ec02e5cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9158c826ea2f43c3a65da1c19d00f5e0","IPY_MODEL_58fef1e77f204c07ad7624e8c9e5da36","IPY_MODEL_59a3f1844f2d4aef85e6baf753ae7d9a"],"layout":"IPY_MODEL_9e6ba2b0bfa84b21aeaeaa9cb3f39093"}},"9158c826ea2f43c3a65da1c19d00f5e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f2daf7c4c1f44c3aa79198b26ce54c4","placeholder":"​","style":"IPY_MODEL_816be08ccae5499f8e682f29bfdf1a30","value":"model.safetensors:  82%"}},"58fef1e77f204c07ad7624e8c9e5da36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_b010e0da41e44d82af28c30ba3015085","max":11406460256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_422158eb8f034deea059064f397b906d","value":9321840640}},"59a3f1844f2d4aef85e6baf753ae7d9a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e1e37318055441f92b67f735312dfed","placeholder":"​","style":"IPY_MODEL_6a185172bf7549a7ab85ceb16372c585","value":" 9.32G/11.4G [03:05&lt;00:29, 71.5MB/s]"}},"9e6ba2b0bfa84b21aeaeaa9cb3f39093":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f2daf7c4c1f44c3aa79198b26ce54c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"816be08ccae5499f8e682f29bfdf1a30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b010e0da41e44d82af28c30ba3015085":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"422158eb8f034deea059064f397b906d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e1e37318055441f92b67f735312dfed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a185172bf7549a7ab85ceb16372c585":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36bbbfe07a0445c9aba3595f7ba98c4d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78ea28d122dc4130a51c3fa541e1f50b","IPY_MODEL_35acc34802d3462087348d527c973d71","IPY_MODEL_6af7f2163b0447a49ce68deb70026171"],"layout":"IPY_MODEL_96148099c79c472da8faa7b5da634666"}},"78ea28d122dc4130a51c3fa541e1f50b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd0b64e41ab1429db887e0ef6f01fb32","placeholder":"​","style":"IPY_MODEL_f9396e35b2954ea9a65a0b83a2e7aade","value":"Generating train split: "}},"35acc34802d3462087348d527c973d71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_888064d5386d45788a1132c651c739f5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2cf01567e8144c45aced45f6d7fd1bd2","value":1}},"6af7f2163b0447a49ce68deb70026171":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0aa40b7e07604765988ebbb4e680f368","placeholder":"​","style":"IPY_MODEL_e8b1cc6ee0724bef84324e932733e64a","value":" 500/0 [00:00&lt;00:00, 3610.98 examples/s]"}},"96148099c79c472da8faa7b5da634666":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd0b64e41ab1429db887e0ef6f01fb32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9396e35b2954ea9a65a0b83a2e7aade":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"888064d5386d45788a1132c651c739f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"2cf01567e8144c45aced45f6d7fd1bd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0aa40b7e07604765988ebbb4e680f368":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8b1cc6ee0724bef84324e932733e64a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31b3c2e7cc814cf7b5ad4c486293f265":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3071e18a7c4d4225be1e989b6abec02b","IPY_MODEL_b0e53b05dda64ed8b76122ecb53a5da7","IPY_MODEL_d20cae9fa9e04b30915bdea5ef85c4f6"],"layout":"IPY_MODEL_84c4b5b01a9f4689b23a10b87f31c1e3"}},"3071e18a7c4d4225be1e989b6abec02b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccd9a6751f5a4a69af758b883656a887","placeholder":"​","style":"IPY_MODEL_f141c387ce2d4eb9aa06d3e680f26939","value":"Map: 100%"}},"b0e53b05dda64ed8b76122ecb53a5da7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e11957043c0e47f09938cb7ffffd3374","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f254998251c64672a49c113c34349888","value":500}},"d20cae9fa9e04b30915bdea5ef85c4f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2f6f0f0a19b48fe9684fe33b394d437","placeholder":"​","style":"IPY_MODEL_3725823ab77e4f8da571826602c41d4b","value":" 500/500 [00:09&lt;00:00, 63.65 examples/s]"}},"84c4b5b01a9f4689b23a10b87f31c1e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccd9a6751f5a4a69af758b883656a887":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f141c387ce2d4eb9aa06d3e680f26939":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e11957043c0e47f09938cb7ffffd3374":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f254998251c64672a49c113c34349888":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2f6f0f0a19b48fe9684fe33b394d437":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3725823ab77e4f8da571826602c41d4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e0b08b8388047e9a15081b4ccb0f775":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ddb719803514f74b3241b5f76c397cc","IPY_MODEL_ab9dbca6bc18484589a4f55f96993b1a","IPY_MODEL_f8401d64f6554e3193a039085b17f32c"],"layout":"IPY_MODEL_15047e24e2c94e0d90ea20c41bf381ac"}},"5ddb719803514f74b3241b5f76c397cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b78eaf50abd43c3a9afb07ea8e441d8","placeholder":"​","style":"IPY_MODEL_5b749f6f6a40441fa8ed3538fa5b0340","value":"Map: 100%"}},"ab9dbca6bc18484589a4f55f96993b1a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf714280f53e4781a5e45f455bb639db","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a631e29abf644794bbc92d29a9bfb9ae","value":500}},"f8401d64f6554e3193a039085b17f32c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_196130ce156f45fbb37802cac2b331ee","placeholder":"​","style":"IPY_MODEL_a1cb13f82fcf4d9bbda8c09361e122e0","value":" 500/500 [00:05&lt;00:00, 74.20 examples/s]"}},"15047e24e2c94e0d90ea20c41bf381ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b78eaf50abd43c3a9afb07ea8e441d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b749f6f6a40441fa8ed3538fa5b0340":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf714280f53e4781a5e45f455bb639db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a631e29abf644794bbc92d29a9bfb9ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"196130ce156f45fbb37802cac2b331ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1cb13f82fcf4d9bbda8c09361e122e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install -q rouge\n","!pip install -q rouge-score\n","!pip install -q evaluate\n","!pip install -q sacrebleu"],"metadata":{"id":"X9-vaVfv-8QP","executionInfo":{"status":"ok","timestamp":1733436907951,"user_tz":480,"elapsed":27751,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"eNrqWQP5BW2A","executionInfo":{"status":"ok","timestamp":1733436927598,"user_tz":480,"elapsed":19650,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import torch\n","\n","from transformers import pipeline, T5Tokenizer, TFT5Model, T5ForConditionalGeneration, AutoTokenizer\n","from transformers import Trainer, TrainingArguments, TrainerCallback\n","from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoModelForSeq2SeqLM\n","\n","#evaluation packages\n","#rogue score\n","from rouge import Rouge\n","from evaluate import load\n","# BERTScore leverages the pre-trained contextual embeddings from BERT and matches words in candidate and reference sentences by cosine similarity.\n","# from bert_score import BERTScorer\n","#bleu score\n","import sacrebleu"]},{"cell_type":"code","source":["# This cell will authenticate you and mount your Drive in the Colab.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRaOR0cLlcek","executionInfo":{"status":"ok","timestamp":1733436928865,"user_tz":480,"elapsed":1270,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"95c65818-1f90-4486-8945-6479aaea90e6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Load Data"],"metadata":{"id":"kpu2HV7SCmOm"}},{"cell_type":"code","source":["!pip install -q datasets # Install the 'datasets' library\n","from datasets import load_dataset # Now you can import the library\n","\n","ds = load_dataset(\"Bilal-Mamji/Medical-summary\")"],"metadata":{"id":"7e5clpxqCyjk","collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733436939828,"user_tz":480,"elapsed":10966,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"49994212-9435-4fa8-e742-9d4affe14394"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Show dataset dict\n","print(ds)\n","\n","# First training input for testing\n","dialogue_sample0 = ds['train']['input'][0]\n","print('First input:')\n","dialogue_sample0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"id":"ew29fiSbDUwm","executionInfo":{"status":"ok","timestamp":1733436939829,"user_tz":480,"elapsed":17,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"c5fa6042-e24b-40b4-c90f-9999f7456fcc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['input', 'output', 'instruction'],\n","        num_rows: 9250\n","    })\n","    validation: Dataset({\n","        features: ['input', 'output', 'instruction'],\n","        num_rows: 500\n","    })\n","    test: Dataset({\n","        features: ['input', 'output', 'instruction'],\n","        num_rows: 250\n","    })\n","})\n","First input:\n"]},{"output_type":"execute_result","data":{"text/plain":["\"Doctor: Hello, how can I help you today?\\nPatient: My son has been having some issues with speech and development. He's 13 years old now.\\nDoctor: I see. Can you tell me more about his symptoms? Does he have any issues with muscle tone or hypotonia?\\nPatient: No, he doesn't have hypotonia. But he has mild to moderate speech and developmental delay, and he's been diagnosed with attention deficit disorder.\\nDoctor: Thank you for sharing that information. We'll run some tests, including an MRI, to get a better understanding of your son's condition. \\n(After the tests)\\nDoctor: The MRI results are in, and I'm glad to say that there are no structural brain anomalies. However, I did notice some physical characteristics. Does your son have any facial features like retrognathia, mild hypertelorism, or a slightly elongated philtrum and thin upper lip?\\nPatient: Yes, he has all of those features. His hands are also broad and short. And his feet have mild syndactyly of the second and third toe, with a sandal gap in both feet.\\nDoctor: Thank you for confirming that. We also conducted Whole Exome Sequencing (WES) analyses, and we found a de novo frameshift variant in his genetic makeup. Specifically, it's Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)). This leads to a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nPatient: What does that mean for my son?\\nDoctor: This genetic variant may be contributing to your son's speech, developmental delay, and attention deficit disorder. It's important that we continue monitoring his progress and provide appropriate support for his development.\\nPatient: What should we do for follow-up?\\nDoctor: Regular visits with a speech and language therapist, an occupational therapist, and a psychologist can help address your son's developmental and attention deficit disorder needs. I will also recommend regular check-ups with me to monitor his growth and overall health.\\nPatient: Thank you, doctor. We will follow your recommendations and keep an eye on his progress.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# ds['train']['input']  # Gets lits of train inputs\n","# ds['train'][0]  # Get's first instance of train data"],"metadata":{"collapsed":true,"id":"cqs4Ga4U61FK","executionInfo":{"status":"ok","timestamp":1733436939829,"user_tz":480,"elapsed":15,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Summary Instructions"],"metadata":{"id":"wq-dsjxFsAx-"}},{"cell_type":"code","source":["basic_instruct = \"Summarize: \"\n","SOAP_instruct = \"Create a medical SOAP summary of this dialogue.: \"\n","SOAP_instruct_full = \"Create a Medical SOAP note summary from the dialogue, following these guidelines: S (Subjective): Summarize the patient's reported symptoms, including chief complaint and relevant history. Rely on the patient's statements as the primary source and ensure standardized terminology. O (Objective): Highlight critical findings such as vital signs, lab results, and imaging, emphasizing important details like the side of the body affected and specific dosages. Include normal ranges where relevant. A (Assessment): Offer a concise assessment combining subjective and objective data. State the primary diagnosis and any differential diagnoses, noting potential complications and the prognostic outlook. P (Plan): Outline the management plan, covering medication, diet, consultations, and education. Ensure to mention necessary referrals to other specialties and address compliance challenges. Considerations: Compile the report based solely on the transcript provided. Maintain confidentiality and document sensitively. Use concise medical jargon and abbreviations for effective doctor communication. Please format the summary in a clean, simple list format without using markdown or bullet points. Use 'S:', 'O:', 'A:', 'P:' directly followed by the text. Avoid any styling or special characters.\""],"metadata":{"id":"LAcXZyeEsDPh","executionInfo":{"status":"ok","timestamp":1733436939829,"user_tz":480,"elapsed":15,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Split and Save Data"],"metadata":{"id":"jDUTLQZ_sTNq"}},{"cell_type":"code","source":["# Separate data by split\n","train_dataset = ds['train']\n","valid_dataset = ds['validation']\n","test_dataset = ds['test']\n","\n","# todo Use a subset of training data for debugging\n","# train_dataset = train_dataset.select(range(150))\n","# valid_dataset = valid_dataset.select(range(50))"],"metadata":{"id":"DZnTjr5vi_-H","executionInfo":{"status":"ok","timestamp":1733436939829,"user_tz":480,"elapsed":15,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train_dataset[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7lJYjtCTm0NJ","executionInfo":{"status":"ok","timestamp":1733436939829,"user_tz":480,"elapsed":15,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"d9eb3d1d-d3c6-4bc5-a178-7fc159778793"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input': \"Doctor: Hello, how can I help you today?\\nPatient: My son has been having some issues with speech and development. He's 13 years old now.\\nDoctor: I see. Can you tell me more about his symptoms? Does he have any issues with muscle tone or hypotonia?\\nPatient: No, he doesn't have hypotonia. But he has mild to moderate speech and developmental delay, and he's been diagnosed with attention deficit disorder.\\nDoctor: Thank you for sharing that information. We'll run some tests, including an MRI, to get a better understanding of your son's condition. \\n(After the tests)\\nDoctor: The MRI results are in, and I'm glad to say that there are no structural brain anomalies. However, I did notice some physical characteristics. Does your son have any facial features like retrognathia, mild hypertelorism, or a slightly elongated philtrum and thin upper lip?\\nPatient: Yes, he has all of those features. His hands are also broad and short. And his feet have mild syndactyly of the second and third toe, with a sandal gap in both feet.\\nDoctor: Thank you for confirming that. We also conducted Whole Exome Sequencing (WES) analyses, and we found a de novo frameshift variant in his genetic makeup. Specifically, it's Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)). This leads to a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nPatient: What does that mean for my son?\\nDoctor: This genetic variant may be contributing to your son's speech, developmental delay, and attention deficit disorder. It's important that we continue monitoring his progress and provide appropriate support for his development.\\nPatient: What should we do for follow-up?\\nDoctor: Regular visits with a speech and language therapist, an occupational therapist, and a psychologist can help address your son's developmental and attention deficit disorder needs. I will also recommend regular check-ups with me to monitor his growth and overall health.\\nPatient: Thank you, doctor. We will follow your recommendations and keep an eye on his progress.\",\n"," 'output': \"S: The patient's mother reports that her 13-year-old son has mild to moderate speech and developmental delays and has been diagnosed with attention deficit disorder. She denies any issues with muscle tone or hypotonia. The patient also exhibits certain physical characteristics, including retrognathia, mild hypertelorism, an elongated philtrum, thin upper lip, broad and short hands, mild syndactyly of the second and third toes, and a sandal gap in both feet.\\nO: An MRI of the brain showed no structural anomalies. Whole Exome Sequencing (WES) revealed a de novo frameshift variant Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)), indicating a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nA: The primary diagnosis is a genetic disorder associated with the identified frameshift mutation, which likely contributes to the patient's speech and developmental delays and attention deficit disorder. The physical characteristics and genetic findings suggest a specific syndrome, which needs further correlation with clinical findings and genetic counseling.\\nP: The management plan includes regular follow-up visits with a speech and language therapist, an occupational therapist, and a psychologist to support the patient's developmental needs and address his attention deficit disorder. Regular medical check-ups will monitor his growth and overall health. Genetic counseling for the family is also recommended to discuss the implications of the genetic findings and potential familial inheritance.\",\n"," 'instruction': \"Create a Medical SOAP note summary from the dialogue, following these guidelines:\\n    S (Subjective): Summarize the patient's reported symptoms, including chief complaint and relevant history. Rely on the patient's statements as the primary source and ensure standardized terminology.\\n    O (Objective): Highlight critical findings such as vital signs, lab results, and imaging, emphasizing important details like the side of the body affected and specific dosages. Include normal ranges where relevant.\\n    A (Assessment): Offer a concise assessment combining subjective and objective data. State the primary diagnosis and any differential diagnoses, noting potential complications and the prognostic outlook.\\n    P (Plan): Outline the management plan, covering medication, diet, consultations, and education. Ensure to mention necessary referrals to other specialties and address compliance challenges.\\n    Considerations: Compile the report based solely on the transcript provided. Maintain confidentiality and document sensitively. Use concise medical jargon and abbreviations for effective doctor communication.\\n    Please format the summary in a clean, simple list format without using markdown or bullet points. Use 'S:', 'O:', 'A:', 'P:' directly followed by the text. Avoid any styling or special characters.\"}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# Save splits to separate csv files, to load only part at a time later\n","train_filepath = 'drive/MyDrive/DS266 Project/data/train.csv'\n","valid_filepath = 'drive/MyDrive/DS266 Project/data/valid.csv'\n","test_filepath = 'drive/MyDrive/DS266 Project/data/test.csv'\n","\n","pd.DataFrame(train_dataset).to_csv(train_filepath, index=False)\n","pd.DataFrame(valid_dataset).to_csv(valid_filepath, index=False)\n","pd.DataFrame(test_dataset).to_csv(test_filepath, index=False)\n","\n","# Save this because we'll need to tell the trainer how many examples we have\n","num_train_examples = len(train_dataset)\n","num_train_examples"],"metadata":{"id":"7dcxtZXWmiVR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733436943538,"user_tz":480,"elapsed":3722,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"c746a2fb-efb4-4164-b159-611334acc0da"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9250"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Remove the full dataset from memory\n","ds = None\n","train_dataset = None\n","valid_dataset = None\n","test_dataset = None"],"metadata":{"id":"2YDWx-weoHoF","executionInfo":{"status":"ok","timestamp":1733436943538,"user_tz":480,"elapsed":6,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Load Models"],"metadata":{"id":"MtAk9k0kV6lD"}},{"cell_type":"code","source":["# Load the pre-trained T5 model and tokenizer\n","model_name = \"google/t5-base\"  # also t5-small and t5-large\n","tokenizer = T5Tokenizer.from_pretrained(model_name)  # Load tokenizer\n","model = T5ForConditionalGeneration.from_pretrained(model_name)  # Load model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":651},"id":"61TT_WHdV50y","executionInfo":{"status":"error","timestamp":1733438871863,"user_tz":480,"elapsed":323,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"ccc9892f-f141-432e-ca78-dac77fae8acb"},"execution_count":24,"outputs":[{"output_type":"error","ename":"OSError","evalue":"google/t5-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/google/t5-base/resolve/main/tokenizer_config.json","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    863\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1377\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1297\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    453\u001b[0m             )\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-67522d97-07ebf3eb675e4681788f3d92;742fa83c-c9f6-48af-bf67-650008d4cea9)\n\nRepository Not Found for url: https://huggingface.co/google/t5-base/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-0d49256f06be>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the pre-trained T5 model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"google/t5-base\"\u001b[0m  \u001b[0;31m# also t5-small and t5-large\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m                     \u001b[0;31m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m                     \u001b[0mfast_tokenizer_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFULL_TOKENIZER_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2132\u001b[0;31m                     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   2133\u001b[0m                         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m                         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m         ) from e\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: google/t5-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"]}]},{"cell_type":"markdown","source":["## Stream Dataset"],"metadata":{"id":"pB7n-nXzoR8A"}},{"cell_type":"code","source":["# Stream load\n","# Hugging face load_dataset(), when only 1 file, it assumes the entire dataset is train data, thus the indexing ['train'] to remove that dictionary key level\n","train_dataset = load_dataset(\"csv\", data_files=train_filepath, streaming=True)['train']\n","valid_dataset = load_dataset(\"csv\", data_files=valid_filepath, streaming=False)['train']    # Set stream to false since it is a much smaller dataset and does not seem to be limiting factor"],"metadata":{"id":"h8iwZ38wooUJ","executionInfo":{"status":"ok","timestamp":1733436947196,"user_tz":480,"elapsed":1412,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["36bbbfe07a0445c9aba3595f7ba98c4d","78ea28d122dc4130a51c3fa541e1f50b","35acc34802d3462087348d527c973d71","6af7f2163b0447a49ce68deb70026171","96148099c79c472da8faa7b5da634666","fd0b64e41ab1429db887e0ef6f01fb32","f9396e35b2954ea9a65a0b83a2e7aade","888064d5386d45788a1132c651c739f5","2cf01567e8144c45aced45f6d7fd1bd2","0aa40b7e07604765988ebbb4e680f368","e8b1cc6ee0724bef84324e932733e64a"]},"outputId":"69388c9f-0618-41b8-bd6c-b35911752fda"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36bbbfe07a0445c9aba3595f7ba98c4d"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Preprocess Encounter Data\n","\n"],"metadata":{"id":"rEh3mZ3rgPfI"}},{"cell_type":"code","source":["## Preprocess: append instructions, set max length,\n","max_length = 600 #TODO Not long enough to capture entire input, but keeping it short to keep memory down\n","\n","def preprocess_data(encounter):\n","    ''' Function to tokenize input and target output '''\n","    orig_text, target_text = encounter['input'], encounter['output']\n","    orig_text = basic_instruct + orig_text      #TODO Add/Change instruction\n","\n","    # Tokenize input dialogue\n","    orig_encoded = tokenizer.batch_encode_plus(\n","        [orig_text],\n","        max_length=max_length,\n","        padding='max_length',\n","        truncation=True,\n","        return_attention_mask=True,\n","        return_tensors='pt'\n","    )\n","\n","    orig_input_ids = orig_encoded['input_ids'][0]\n","    orig_attention_mask = orig_encoded['attention_mask'][0]\n","\n","    # Tokenize ground truth summary\n","    target_encoded = tokenizer.batch_encode_plus(\n","        [target_text],\n","        max_length=max_length,\n","        padding='max_length',\n","        truncation=True,\n","        return_attention_mask=True,\n","        return_tensors='pt'\n","    )\n","\n","    label_ids = target_encoded['input_ids'][0]\n","\n","    # Check text processing step\n","    # print('--------')\n","    # print(orig_text)\n","    # print(target_text)\n","\n","    return {'input_ids': orig_input_ids,\n","            'attention_mask': orig_attention_mask,\n","            'labels': label_ids}"],"metadata":{"collapsed":true,"id":"Lte8d3_cptl6","executionInfo":{"status":"ok","timestamp":1733436947196,"user_tz":480,"elapsed":10,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Map the preprocessing function to the datasets (it will be called when batches are loaded)\n","\n","train_dataset = train_dataset.map(preprocess_data)\n","valid_dataset = valid_dataset.map(preprocess_data)"],"metadata":{"id":"PlVaHWces8ho","executionInfo":{"status":"ok","timestamp":1733436957621,"user_tz":480,"elapsed":10434,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["31b3c2e7cc814cf7b5ad4c486293f265","3071e18a7c4d4225be1e989b6abec02b","b0e53b05dda64ed8b76122ecb53a5da7","d20cae9fa9e04b30915bdea5ef85c4f6","84c4b5b01a9f4689b23a10b87f31c1e3","ccd9a6751f5a4a69af758b883656a887","f141c387ce2d4eb9aa06d3e680f26939","e11957043c0e47f09938cb7ffffd3374","f254998251c64672a49c113c34349888","c2f6f0f0a19b48fe9684fe33b394d437","3725823ab77e4f8da571826602c41d4b"]},"outputId":"1cff064a-e5ee-487a-c6d3-6a7a7968caa1"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31b3c2e7cc814cf7b5ad4c486293f265"}},"metadata":{}}]},{"cell_type":"code","source":["valid_dataset[0]['input_ids']\n","tokenizer.decode(valid_dataset[0]['input_ids'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"id":"xmo4Xyq42ZZM","executionInfo":{"status":"ok","timestamp":1733436957621,"user_tz":480,"elapsed":12,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"9cff800d-1036-467c-b33f-f37e925dbc62"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Summarize: Doctor: Hello! I see that you were referred to our hospital for a lung adenocarcinoma measuring 28 mm in your right upper lobe. Is that correct? Patient: Yes, that's right. Doctor: We have planned a UVATS procedure to resect the tumor. Are you familiar with this procedure? Patient: Not really, can you explain it to me? Doctor: Of course. During the procedure, you will be placed in the left lateral decubitus position under general anesthesia. We will then make a 4-cm skin incision for the main port in the sixth intercostal space at the anterior axillary line. Patient: Okay, I see. Doctor: A wound retractor will be used to allow the insertion of a flexible thoracoscope, endoscopic autosuturing device, and vessel-sealing device via the main port incision. This will also allow us to extract the specimen after the operation. Patient: Hmm, I understand. Doctor: During the operation, we found an incomplete interlobar fissure between the upper and middle lobe, as well as abnormal lobulation of the upper lobe. Therefore, we carried out a modified marionette technique. Patient: What does that involve? Doctor: First, an Internal organ retractor was inserted into the thoracic cavity using a clip applier. This allowed the retractor to grasp the targeted lung parenchyma properly. Patient: Okay. Doctor: Second, we prepared two sets of looped 1-0 nylon-threaded 18-gauge injection needles. These needles were optimally pierced through the thoracic wall separately. Patient: And then what happened? Doctor: Finally, both ends of the 1-0 nylon thread attached to the Internal organ retractor were pulled out through the looped nylon. This allowed us to perform the procedure more effectively. Patient: I see. So, what are the follow-up requirements for this procedure? Doctor: You will need regular check-ups and monitoring to ensure that the tumor has been completely removed and that there are no complications. We will provide you with more information regarding your follow-up appointments. Patient: Thank you, doctor. I appreciate the explanation. Doctor: You're welcome! If you have any more questions, feel free to ask. We're here to help. Patient: I think I understand everything now. Thanks again. Doctor: No problem, take care, and we'll see you at your follow-up appointment.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"RunKSmm6twLu"}},{"cell_type":"code","source":["#TODO Modify this filepath to where you want to save the model after fine-tuning\n","dir_path = 'drive/MyDrive/DS266 Project/model_checkpoints/'\n","file_path = dir_path + 't5base-finetuned-soap_01'"],"metadata":{"id":"EEI7ofKbsb3b","executionInfo":{"status":"ok","timestamp":1733436957621,"user_tz":480,"elapsed":11,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["#TODO Specify batch size and other training arguments\n","\n","batch_size = 16  #todo\n","num_epochs = 3\n","eval_steps = 50\n","\n","\n","args = Seq2SeqTrainingArguments(\n","    file_path,\n","    evaluation_strategy='steps',\n","    eval_steps = eval_steps,\n","    logging_steps = eval_steps,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    gradient_checkpointing=True,  #todo Decrease computational cost\n","    # gradient_accumulation_steps=2,  #todo  Accumulate gradients to decrease computational cost\n","    max_steps=int(num_epochs * num_train_examples / batch_size)   # Streaming dataset, we don't know how much data. Steps are the number of batches per epoch * num of epochs\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fuHUYPlXty3F","executionInfo":{"status":"ok","timestamp":1733436957622,"user_tz":480,"elapsed":11,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"812bb9bc-c1bc-4062-bd40-d201ef864d63"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# log examples\n","\n","# def compute_metrics(eval_predictions):\n","#   # Get only the first 5 predictions, labels, and inputs\n","#     predictions, labels, inputs = eval_predictions[0][:5], eval_predictions[1][:5], eval_predictions[2][:5]\n","\n","#     decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","#     decoded_inputs = tokenizer.batch_decode(inputs, skip_special_tokens=True)\n","\n","#     for input_text, pred, label in zip(decoded_inputs, decoded_preds, decoded_labels):\n","#         print(f\"Input Text: {input_text}\\nPredicted Summary: {pred}\\nGround Truth: {label}\\n-------------\")\n","\n","    # ... other metrics calculation ...\n","    # return {\"rouge-l\": rouge_score(decoded_preds, decoded_labels)}\n"],"metadata":{"id":"aLjzWKRTwVND","executionInfo":{"status":"ok","timestamp":1733436957622,"user_tz":480,"elapsed":10,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# from transformers import TrainerCallback\n","\n","# class CustomCallback(TrainerCallback):\n","#     def on_train_step_end(self, args, state, control, **kwargs):\n","#         print('callback function run')\n","#         if state.global_step % 50 == 0:\n","#             print('divisible by 50 step')\n","#             # Get a batch of validation data\n","#             eval_dataloader = self.trainer.get_eval_dataloader()\n","#             batch = next(iter(eval_dataloader))\n","\n","#             # Move the batch to the device\n","#             batch = {k: v.to(self.trainer.device) for k, v in batch.items()}\n","\n","#             # Generate predictions\n","#             with torch.no_grad():\n","#                 outputs = self.trainer.model(**batch)\n","#                 logits = outputs.logits\n","\n","#             # Decode predictions and labels\n","#             predictions = torch.argmax(logits, dim=-1)\n","#             decoded_preds = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","#             decoded_labels = self.tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n","#             decoded_inputs = self.tokenizer.batch_decode(batch['input_ids'], skip_special_tokens=True)\n","\n","#             # Log the first 5 examples\n","#             for input_text, pred_text, target_text in zip(decoded_inputs[:5], decoded_preds[:5], decoded_labels[:5]):\n","#                 print(f\"Input: {input_text}\")\n","#                 print(f\"Prediction: {pred_text}\")\n","#                 print(f\"Target: {target_text}\")\n","#                 print(\"-\" * 50)"],"metadata":{"id":"akMKMvrcZnoV","executionInfo":{"status":"ok","timestamp":1733436957622,"user_tz":480,"elapsed":9,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Define the trainer, passing in the model, training args, and data generators\n","\n","trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=train_dataset,\n","    eval_dataset=valid_dataset,\n","    # compute_metrics = compute_metrics,\n","    # callbacks=[CustomCallback()]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L4rptoG6wZVC","executionInfo":{"status":"ok","timestamp":1733436959726,"user_tz":480,"elapsed":2113,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"b5ae156c-ecec-47e1-b403-d699ddef3d7b"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}]},{"cell_type":"code","source":["# free up GPU memory\n","import gc\n","import torch\n","\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","# Gemini suggestion to prevent fragmentation\n","!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"],"metadata":{"id":"gPvQ4nVhdEus","executionInfo":{"status":"ok","timestamp":1733436960123,"user_tz":480,"elapsed":404,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Call train\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":539},"id":"E0gWOnbuweVa","outputId":"54ae4c2f-d523-4800-fda6-f5b4abbcdabd","executionInfo":{"status":"error","timestamp":1733437067911,"user_tz":480,"elapsed":107792,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjonnyluo\u001b[0m (\u001b[33mjonnyluo-university-of-california-berkeley\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.18.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20241205_221603-m2kdqki4</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/jonnyluo-university-of-california-berkeley/huggingface/runs/m2kdqki4' target=\"_blank\">drive/MyDrive/DS266 Project/model_checkpoints/t5base-finetuned-soap_01</a></strong> to <a href='https://wandb.ai/jonnyluo-university-of-california-berkeley/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/jonnyluo-university-of-california-berkeley/huggingface' target=\"_blank\">https://wandb.ai/jonnyluo-university-of-california-berkeley/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/jonnyluo-university-of-california-berkeley/huggingface/runs/m2kdqki4' target=\"_blank\">https://wandb.ai/jonnyluo-university-of-california-berkeley/huggingface/runs/m2kdqki4</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='1734' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  12/1734 01:20 < 3:51:58, 0.12 it/s, Epoch 0.01/9223372036854775807]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-61bcf1cf9178>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Call train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2123\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2124\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2479\u001b[0m                     )\n\u001b[1;32m   2480\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m                     if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3610\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3611\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3612\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3613\u001b[0m             \u001b[0;31m# Finally we need to normalize the loss for reporting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3614\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2241\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## Load from Checkpoint\n"],"metadata":{"id":"PGJTt2VZsC6M"}},{"cell_type":"code","source":["# Set directory to desired model\n","file_path = dir_path + 't5base-finetuned-soap'\n","model_saved = T5ForConditionalGeneration.from_pretrained(file_path + '/checkpoint-1734')"],"metadata":{"id":"NNeNEBuusClM","executionInfo":{"status":"ok","timestamp":1733339499836,"user_tz":480,"elapsed":11692,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# Generate: Validate and Test"],"metadata":{"id":"c7pcrkFLt0aV"}},{"cell_type":"code","source":["## Try using preprocess mapper to add instructions\n","## Validation data check\n","\n","# Move the model to the GPU\n","# model_saved = model_saved.cuda()  # Move the model to the GPU\n","\n","# Preprocess: Tokenize, add instructions\n","valid_dataset = valid_dataset.map(preprocess_data)\n","\n","for i, encounter in enumerate(valid_dataset):\n","    if i >= 5:\n","        break  #TODO Stop after 3 iterations\n","\n","    print(encounter['input'])   # Print input dialogue\n","    print(encounter['output'])  # Print ground truth\n","\n","    # Convert input_ids to tensor before generation\n","    input_ids_tensor = torch.tensor(encounter['input_ids']).unsqueeze(0)  # Add batch dimension\n","    # Generate summary prediction\n","    predict_output_ids = model_saved.generate(input_ids_tensor, min_length=200, max_length=400,   #TODO set the model\n","                                              do_sample = True, num_beams=5, no_repeat_ngram_size=3,\n","                                              early_stopping=True, temperature=0)\n","    # Decode tokens to human text\n","    print([tokenizer.decode(out_ids, skip_special_tokens=True,\n","                               clean_up_tokenization_spaces=False) for out_ids in predict_output_ids])\n","    print('---------')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["7e0b08b8388047e9a15081b4ccb0f775","5ddb719803514f74b3241b5f76c397cc","ab9dbca6bc18484589a4f55f96993b1a","f8401d64f6554e3193a039085b17f32c","15047e24e2c94e0d90ea20c41bf381ac","6b78eaf50abd43c3a9afb07ea8e441d8","5b749f6f6a40441fa8ed3538fa5b0340","bf714280f53e4781a5e45f455bb639db","a631e29abf644794bbc92d29a9bfb9ae","196130ce156f45fbb37802cac2b331ee","a1cb13f82fcf4d9bbda8c09361e122e0"]},"id":"oJRdnJo3vAOd","executionInfo":{"status":"ok","timestamp":1733339766190,"user_tz":480,"elapsed":266360,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"28367dbc-f895-4029-e720-22df0181619a"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e0b08b8388047e9a15081b4ccb0f775"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Doctor: Hello! I see that you were referred to our hospital for a lung adenocarcinoma measuring 28 mm in your right upper lobe. Is that correct?\n","Patient: Yes, that's right.\n","Doctor: We have planned a UVATS procedure to resect the tumor. Are you familiar with this procedure?\n","Patient: Not really, can you explain it to me?\n","Doctor: Of course. During the procedure, you will be placed in the left lateral decubitus position under general anesthesia. We will then make a 4-cm skin incision for the main port in the sixth intercostal space at the anterior axillary line.\n","Patient: Okay, I see.\n","Doctor: A wound retractor will be used to allow the insertion of a flexible thoracoscope, endoscopic autosuturing device, and vessel-sealing device via the main port incision. This will also allow us to extract the specimen after the operation.\n","Patient: Hmm, I understand.\n","Doctor: During the operation, we found an incomplete interlobar fissure between the upper and middle lobe, as well as abnormal lobulation of the upper lobe. Therefore, we carried out a modified marionette technique.\n","Patient: What does that involve?\n","Doctor: First, an Internal organ retractor was inserted into the thoracic cavity using a clip applier. This allowed the retractor to grasp the targeted lung parenchyma properly.\n","Patient: Okay.\n","Doctor: Second, we prepared two sets of looped 1-0 nylon-threaded 18-gauge injection needles. These needles were optimally pierced through the thoracic wall separately.\n","Patient: And then what happened?\n","Doctor: Finally, both ends of the 1-0 nylon thread attached to the Internal organ retractor were pulled out through the looped nylon. This allowed us to perform the procedure more effectively.\n","Patient: I see. So, what are the follow-up requirements for this procedure?\n","Doctor: You will need regular check-ups and monitoring to ensure that the tumor has been completely removed and that there are no complications. We will provide you with more information regarding your follow-up appointments.\n","Patient: Thank you, doctor. I appreciate the explanation.\n","Doctor: You're welcome! If you have any more questions, feel free to ask. We're here to help.\n","Patient: I think I understand everything now. Thanks again.\n","Doctor: No problem, take care, and we'll see you at your follow-up appointment.\n","S: The patient confirmed a diagnosis of lung adenocarcinoma in the right upper lobe, measuring 28 mm. The patient expressed unfamiliarity with the planned UVATS procedure and required explanation about the process and follow-up care.\n","O: During the UVATS procedure, an incomplete interlobar fissure between the upper and middle lobe and abnormal lobulation of the upper lobe were noted. A modified marionette technique was utilized involving the insertion of an internal organ retractor and the use of looped 1-0 nylon-threaded 18-gauge injection needles. The patient was placed in the left lateral decubitus position, and a 4-cm skin incision was made in the sixth intercostal space at the anterior axillary line for the main port.\n","A: Primary diagnosis is lung adenocarcinoma in the right upper lobe. The UVATS procedure was completed with modifications due to anatomical variations. The assessment during surgery did not indicate any immediate complications from the procedure.\n","P: The patient is scheduled for regular follow-up appointments to monitor for complete tumor removal and to check for any postoperative complications. The patient will be provided with detailed information regarding the schedule and nature of these follow-ups. Further education on the procedure and postoperative care will be provided as needed to ensure understanding and compliance.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[\"S: The patient reports being referred for a lung adenocarcinoma measuring 28 mm in the right upper lobe. The patient has not been familiar with the procedure. O: During the UVATS procedure, the patient was placed in the left lateral decubitus position under general anesthesia, followed by a 4-cm skin incision for the main port in the sixth intercostal space at the anterior axillary line. A wound retractor was used to allow the insertion of a flexible thoracoscope, endoscopic autosuturing device, and vessel-sealing device. Post-surgery, an incomplete interlobar fissure was found between the upper and midlobes of the lung. A: The primary diagnosis is a recurrent lung tumor with a history of lung cancer. Differential diagnoses could include other causes of lung tumors, but these are less likely given the patient's history and clinical presentation. P: The management plan includes a UVATS operation to resect the tumor. A follow-up appointment will be scheduled to monitor the progress of the procedure and monitor the tumor's progress.\"]\n","---------\n","Doctor: Hello! You mentioned that you came in for an evaluation and treatment for eyebrow alopecia. Can you tell me more about that and if you've experienced any other hair loss on your body?\n","Patient: Hi, doctor. Yes, I've noticed my eyebrows have been thinning, but I haven't experienced hair loss anywhere else on my body.\n","Doctor: Alright. Have you done anything to your eyebrows in the past, like plucking them with tweezers?\n","Patient: Yes, I used to shape my eyebrows by plucking them with tweezers.\n","Doctor: Do you have any other medical conditions or concerns that you'd like me to be aware of?\n","Patient: No, I don't have any other medical conditions.\n","Doctor: Okay, let me examine your eyebrows and other areas on your body to check for any signs of alopecia. *Examines patient* I see sparse and thin black hairs on your eyebrows but no signs of hair loss elsewhere, such as your frontal hairline or temporal area. \n","Patient: That's good to hear.\n","Doctor: Based on my examination, I'm diagnosing you with idiopathic eyebrow hypotrichosis. I'm going to prescribe you a bimatoprost 0.03% solution to apply to the affected areas daily. \n","Patient: Okay, thank you.\n","Doctor: Just so you know, improvement in your eyebrow hypotrichosis will be gradual, so you'll need to be patient. I'd like to see you for periodic follow-up visits every two months to monitor your progress.\n","Patient: Alright, that sounds reasonable.\n","Doctor: *During follow-up visits* How has your compliance with the daily application of the bimatoprost 0.03% solution been?\n","Patient: I've been using it once a day as you instructed.\n","Doctor: Great! I can see increased hair growth and thickening of your eyebrow hairs. Have you experienced any treatment-associated side effects?\n","Patient: No, I haven't had any side effects from the treatment.\n","Doctor: That's excellent! After eight months, it looks like you have complete regrowth of your eyebrows. We'll continue with the daily topical treatment of bimatoprost 0.03% solution to maintain these results.\n","Patient: Thank you, doctor. I'm really happy with the progress and the treatment.\n","S: The patient, a female with no significant medical history, presented with the chief complaint of eyebrow thinning, specifically noting no other areas of hair loss on her body. She reported a history of eyebrow plucking, which could be relevant to her current condition.\n","O: Physical examination revealed sparse and thin black hairs on the eyebrows with no signs of hair loss on the frontal hairline or temporal areas. No other abnormalities were noted during the examination. The patient has been using bimatoprost 0.03% solution daily as prescribed, with no reported side effects.\n","A: The primary diagnosis is idiopathic eyebrow hypotrichosis. The patient's history and clinical findings support this diagnosis, with no evidence of other dermatological or systemic diseases contributing to the hair loss. The prognosis is good, given the positive response to treatment observed during follow-up.\n","P: The management plan includes continued daily application of bimatoprost 0.03% solution to the affected areas to maintain hair regrowth. The patient is scheduled for periodic follow-up visits every two months to monitor progress and adherence to the treatment regimen. Education on the gradual nature of treatment response and encouragement of patient compliance have been emphasized. No referral to other specialties is needed at this time.\n","[\"S: The patient reports noticing thinning eyebrows but has not experienced hair loss elsewhere on the body. The patient has a history of plucking eyebrows with tweezers. No other medical conditions or concerns were reported. O: Physical examination revealed sparse and thin black hairs on the eyebrows, with no hair loss at the frontal hairline or temporal area. Laboratory tests showed alopecia with a white blood cell count of 95% on the thigh, and a hemoglobin level of 11% on the right hemisphere. A: The primary diagnosis is hair loss in the forehead, frontal, and temporal areas. Differential diagnoses could include other causes of hair loss, but these are less likely given the imaging findings. P: The management plan includes a follow-up appointment to monitor the patient's condition and any other concerns. Follow-up appointments will be scheduled to assess the severity of the hair loss. A\"]\n","---------\n","Doctor: Good morning, ma'am. I see you were admitted to the emergency department with a complaint of palpitations that started a few hours ago. Can you describe the palpitations for me?\n","Patient: Hi, doctor. Yeah, my heart has been beating really fast and irregularly for the past few hours. It's quite uncomfortable.\n","Doctor: I understand. We've done a 12-lead ECG, which suggests that you have atrial fibrillation. I also noticed in your medical history that you've been taking oral anticoagulation therapy for recurrent episodes of atrial fibrillation and topiramate for essential tremor in your arms. Is that correct?\n","Patient: Yes, that's right. I've had these issues before, and the medications help manage them.\n","Doctor: After you were admitted, we administered an intravenous dose of amiodarone to help with your current symptoms. Your new 12-lead ECG is now compatible with atrial flutter, having a cycle length of 240 ms and a 4:1 atrioventricular response.\n","Patient: Oh, okay. What does that mean?\n","Doctor: Atrial flutter is a different type of abnormal heart rhythm, but it's related to atrial fibrillation. The cycle length and atrioventricular response we observed indicate that your heart rhythm has changed, but it's still not regular.\n","Patient: I see. So, what's the next step?\n","Doctor: We wanted to further evaluate the underlying heart rhythm, so we performed a two-dimensional transthoracic echocardiography (2D TTE) on you. This is an ultrasound of your heart to see how it's functioning.\n","Patient: And what did you find?\n","Doctor: We measured the transmitral flow using pulsed-wave Doppler and found a diastolic pattern with a normal atrial rhythm. This means that your heart is functioning relatively well despite the abnormal rhythm.\n","Patient: That's a relief. What do we do now?\n","Doctor: We will continue to monitor your heart rhythm and adjust your medications as needed. It's important for you to keep taking your prescribed medications and follow up with your cardiologist regularly for further evaluation and management.\n","Patient: Alright, doctor. I appreciate your help. I'll make sure to follow up with my cardiologist and take my medications as prescribed.\n","Doctor: You're welcome. If you experience any worsening symptoms or have any concerns, do not hesitate to contact your healthcare team or come back to the emergency department. Take care and stay safe.\n","S: The patient, a female with a history of recurrent atrial fibrillation and essential tremor, presented to the emergency department with palpitations described as fast and irregular, which started a few hours prior to admission. She reports discomfort associated with these symptoms. The patient confirms ongoing treatment with oral anticoagulation therapy and topiramate.\n","O: Initial 12-lead ECG indicated atrial fibrillation. Post-administration of intravenous amiodarone, a follow-up 12-lead ECG showed atrial flutter with a cycle length of 240 ms and a 4:1 atrioventricular response. Two-dimensional transthoracic echocardiography (2D TTE) revealed a diastolic pattern with a normal atrial rhythm, indicating relatively good cardiac function despite the abnormal rhythm.\n","A: The primary diagnosis is atrial flutter, previously managed as atrial fibrillation. The patient's heart function is stable as evidenced by the 2D TTE findings, but the presence of atrial flutter necessitates ongoing monitoring and possible adjustment of her current therapeutic regimen.\n","P: Continue monitoring the patient's heart rhythm and adjust medications as necessary. The patient is advised to adhere strictly to her prescribed medication regimen and schedule regular follow-up visits with her cardiologist. She is also instructed to seek immediate medical attention if symptoms worsen or new concerns arise.\n","[\"S: The patient, a female with a history of atrial fibrillation treated with oral anticoagulation therapy and topiramate, presented with palpitations that started a few hours ago. She described the palpations as fast and irregular. She was previously treated with amiodarone, which was administered intravenously. O: The 12-lead ECG showed atrial flutter with 240 ms cycle length and a 4:1 atrioventricular response. The patient's previous medications include a recurrent episode of adipose tissue thrombocytopenia, and tachycardia. A: The primary diagnosis is a diastolic heart disease (TBS), characterized by rapid heart beats and irregular heart rhythms. Differential diagnoses could include other causes of heart failure, but these are less likely given the clinical presentation and clinical presentation. P: The management plan includes discontinuation of the medication and reintroduction of the symptom management plan. The plan includes a follow-up appointment to monitor the patient’s heart rate and heart rate, and the patient will be monitored for any changes in heart rate or heart rate.\"]\n","---------\n","Doctor: Hello, I see that you were admitted to our hospital due to ecchymosis on both lower extremities. Can you tell me more about your medical history?\n","Patient: Yes, three years before admission, I was diagnosed with ITP through laboratory tests, including antibodies against platelet glycoprotein IIb/IIIa and GP IV, and bone marrow aspiration. I was treated successfully with corticosteroids. I also have a history of nontuberculosis mycobacterial infection.\n","Doctor: I see. What treatment were you on before coming here?\n","Patient: I was taking prednisolone, clarithromycin, rifampicin, and ethambutol hydrochloride.\n","Doctor: Okay. I have your recent examination results here. Two weeks before admission, your platelet counts were normal, at 185 × 10^9/l. However, on admission, your laboratory findings showed a significant drop in platelet count, to 3.0 × 10^9/l. Your biochemical parameters and coagulation values were within the normal limit, and antibodies against Helicobacter pylori, hepatitis C virus, hepatitis B virus, and HIV were negative. Based on this, we diagnosed you with acute exacerbation of chronic ITP.\n","Patient: Oh, no. What will be my treatment now?\n","Doctor: We started you on high-dose IVIG, PSL (40 mg/day), and romiplostim (1 µg/kg). However, during the next four days, you developed respiratory failure with a PaO2/FiO2 ratio of approximately 250. We performed a computed tomography (CT) on the fourth day of hospitalization, which revealed ground-glass opacities with marginal infiltration in both lung fields. This led us to diagnose you with alveolar hemorrhage. \n","Patient: That's terrible. What happened next?\n","Doctor: As your dyspnea worsened gradually, we initiated noninvasive positive pressure ventilation (NPPV) to help you breathe. On the 11th day of hospitalization, we increased the dose of romiplostim to 10 µg/kg and administered pulsed doses of methyl-PSL (1000 mg/day for 3 days) along with a second cycle of IVIG.\n","Patient: Did that help?\n","Doctor: Yes, by the 21st day of hospitalization, your platelet count recovered, and you were discharged without any complications.\n","Patient: That's a relief. What's my current situation?\n","Doctor: Your platelet count has remained normal while being treated with 12.5 mg of prednisolone. We will continue to monitor your condition and adjust your treatment as necessary. Make sure to attend any follow-up appointments and report any new symptoms or concerns.\n","Patient: Thank you, doctor. I appreciate your help and will make sure to follow your instructions.\n","S: The patient, previously diagnosed with Immune Thrombocytopenia (ITP) and treated with corticosteroids, was admitted with ecchymosis on both lower extremities. The patient reported a history of nontuberculosis mycobacterial infection and was on prednisolone, clarithromycin, rifampicin, and ethambutol hydrochloride prior to admission.\n","O: On admission, the patient's platelet count was significantly reduced to 3.0 × 10^9/l from a previous normal count of 185 × 10^9/l. Biochemical parameters and coagulation values were normal. Tests for Helicobacter pylori, hepatitis C and B viruses, and HIV were negative. CT imaging on the fourth day showed ground-glass opacities with marginal infiltration in both lung fields, indicative of alveolar hemorrhage. The patient developed respiratory failure with a PaO2/FiO2 ratio of approximately 250.\n","A: The primary diagnosis is an acute exacerbation of chronic ITP, complicated by alveolar hemorrhage. The patient's history of ITP and recent exacerbation, along with the development of respiratory complications, guided the diagnosis and treatment.\n","P: Treatment initiated with high-dose IVIG, PSL (40 mg/day), and romiplostim (1 µg/kg), escalated to 10 µg/kg due to worsening condition. Pulsed doses of methyl-PSL (1000 mg/day for 3 days) and a second cycle of IVIG were administered. Noninvasive positive pressure ventilation (NPPV) was used for respiratory support. The patient's treatment will continue with monitoring and adjustments as necessary, including maintaining a dose of prednisolone at 12.5 mg. Follow-up appointments are scheduled to monitor the patient's condition and platelet count.\n","['S: The patient, admitted due to ecchymosis on both lower extremities, reports a history of ITP diagnosed three years ago through laboratory tests including antibodies against platelet glycoprotein IIb/IIIa and GP IV, bone marrow aspiration, and nontuberculosis mycobacterial infection. The patient was previously treated with corticosteroids and prednisolone, clarithromycin, rifampicin, and ethambutol hydrochloride. O: On examination, platelet counts were normal at 185  109/l. Biochemical parameters and coagulation values were within normal limits, and antibodies against Helicobacter pylori were within the normal limit. Laboratory findings showed a significant drop in platelet count to 3.0 109/10/l, with normal hemoglobin levels and antigen levels. Immunohistochemistry was within normal ranges. CT scan revealed a squamous cell carcinoma (SCC) in the left upper extremity. A: The primary diagnosis is SCC based on the clinical presentation and clinical presentation. Differential diagnoses could include other causes of SCC']\n","---------\n","Doctor: Hello, I see you've been admitted to our clinic for delivery at the 37th week of your gestation. Can you tell me a bit about your pregnancy history? \n","Patient: Sure, this is my sixth pregnancy. I have two children and had three abortions. I also had one previous cesarean section delivery.\n","Doctor: Thank you for sharing that. I have your preoperative blood test results here. Your hemoglobin is 10.8 g/dL, prothrombin time (PT) is 10.5 seconds, activated partial thromboplastin time (aPTT) is 29 seconds, international normalized ratio is 2.3, and platelet count is 385x109/L.\n","Patient: Hmm, okay.\n","Doctor: We also performed a transabdominal sonography and magnetic resonance imaging on you. The results show total placenta previa and myometrial invasion to the urinary bladder at the anterior wall of your uterus. \n","Patient: Oh, that sounds concerning.\n","Doctor: Yes, it can be. You mentioned earlier that you would prefer a conservative approach rather than hysterectomy in case of massive bleeding, is that correct?\n","Patient: Yes, that's right.\n","Doctor: After the cesarean delivery of your baby through a Pfannenstiel incision and removal of the placenta, we detected a 5-6 cm area of tissue loss at the anterior wall of the uterus. There was also bleeding from the cervix and posterior wall of the bladder.\n","Patient: Oh no, what did you do?\n","Doctor: We applied pelvic packing on the pelvic vessels for 20 minutes and sutured the bleeding sites with 1.0 polyglactine sutures. We also placed a Sengstaken-Blakemore balloon catheter in the uterus before suturing.\n","Patient: And did that help?\n","Doctor: We filled the stomach balloon with 250 mL saline and the esophageal balloon with 400 mL saline to provide compression on the lower uterine isthmic and cervical bleeds. However, bleeding continued.\n","Patient: What happened next?\n","Doctor: Bilateral uterine and hypogastric artery ligations were planned due to the hemorrhage. During the procedure, the left external iliac artery was accidentally held and bonded as the left hypogastric artery, but we released it within a minute after distinguishing the vessels.\n","Patient: Oh, I see. \n","Doctor: Following that, we successfully ligated the uterine and hypogastric arteries on both sides. You lost about 2000 cc of blood due to the intraoperative hemorrhage, which we measured by adding 1650 cc blood in the aspirator and counting the gauzes.\n","Patient: That's a lot of blood.\n","Doctor: Yes, it is. We gave you erythrocyte suspension (3 units preoperatively and 4 unites postoperatively) and 3 packs of fresh frozen plasma to help with the blood loss.\n","Patient: Thank you, doctor. I appreciate all that you did to help me during the delivery.\n","S: The patient, a 37-week pregnant woman with a history of two live births, three abortions, and one previous cesarean section, presented for delivery. She expressed a preference for conservative management over hysterectomy in the event of massive bleeding.\n","O: Hemoglobin was 10.8 g/dL, prothrombin time (PT) 10.5 seconds, activated partial thromboplastin time (aPTT) 29 seconds, international normalized ratio (INR) 2.3, and platelet count 385x10^9/L. Imaging revealed total placenta previa and myometrial invasion into the urinary bladder. During cesarean delivery, a 5-6 cm area of tissue loss at the anterior wall of the uterus was noted, with bleeding from the cervix and posterior bladder wall. Pelvic packing and suturing were performed, followed by placement of a Sengstaken-Blakemore balloon catheter. Despite these measures, bleeding continued, leading to bilateral uterine and hypogastric artery ligations. The patient lost approximately 2000 cc of blood. She received 3 units of erythrocyte suspension preoperatively and 4 units postoperatively, along with 3 packs of fresh frozen plasma.\n","A: The patient was diagnosed with total placenta previa and myometrial invasion, complicated by significant intraoperative hemorrhage. The accidental temporary bonding of the left external iliac artery was promptly corrected. The patient's condition stabilized following the surgical interventions.\n","P: Continue monitoring hemoglobin levels and coagulation parameters closely. Administer iron supplements and consider additional blood transfusions if necessary. Provide postoperative care including pain management and infection prevention. Schedule follow-up appointments for wound care and psychological support considering the traumatic nature of the delivery. Educate the patient on signs of infection or complications to watch for during recovery.\n","[\"S: The patient, a 37-week pregnant woman with a history of three abortions and one cesarean section, presents for delivery at the 37th week of gestation. She reports a conservative approach to hysterectomy in case of massive bleeding. O: Preoperative blood tests show hemoglobin at 10.8 g/dL, prothrombin time (10.5 seconds), activated partial thromboplastin time (aPTT) at 29 seconds, international normalized ratio at 2.3, and platelet count at 385x109/L. Transabdominal sonography and magnetic resonance imaging show total placenta previa and myometrial invasion to the urinary bladder at the anterior wall of the uterus. A: The primary diagnosis is a large placental invasion due to a significant placento previa. Differential diagnoses could include other causes of uterine bleeding, but these are less likely given the patient's pregnancy history. P: The management plan includes a resuscitation of the pelvis and resection of the bladder. Post-surgery, the patient will be monitored for any complications or complications. The patient is advised to follow up with the doctor if any complications arise.\"]\n","---------\n"]}]},{"cell_type":"code","source":["# # Reduce unnecessary output\n","# # transformers.logging.set_verbosity_error()\n","\n","\n","# # Move the model to the GPU\n","# # model_saved = model_saved.cuda()  # Move the model to the GPU\n","\n","# # Check some validation outputs\n","# for encounter in valid_dataset.select(range(3)):\n","#     input = encounter['input']    # Get input dialogue from encounter\n","#     print(input)\n","\n","#     # Append instruction and tokenize input\n","#     predict_inputs = tokenizer([basic_instruct + input], return_tensors='pt')\n","#     # Move input tensors to the GPU\n","#     # predict_inputs = predict_inputs.to('cuda') #This line moves the input tensors to the same device as the model.\n","#     # Generate summary through decoding\n","#     predict_output_ids = model_saved.generate(predict_inputs['input_ids'], min_length=200, max_length=400,\n","#                                               num_beams=5, no_repeat_ngram_size=3)\n","#     # Decode tokens to human text\n","#     print([tokenizer.decode(out_ids, skip_special_tokens=True,\n","#                                clean_up_tokenization_spaces=False) for out_ids in predict_output_ids])\n","#     print('---------')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"UQV8CgcvUS7o","executionInfo":{"status":"error","timestamp":1733186111991,"user_tz":480,"elapsed":208,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"972f4006-6025-4ad0-b931-ffccd2777bee","collapsed":true},"execution_count":23,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'IterableDataset' object has no attribute 'select'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-8954c22c9ac3>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Check some validation outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mencounter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencounter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;31m# Get input dialogue from encounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'IterableDataset' object has no attribute 'select'"]}]},{"cell_type":"markdown","source":["# Evaluator"],"metadata":{"id":"tlXnMZ-zoxxT"}},{"cell_type":"code","source":["def generate_predictions(test_dataset, model, tokenizer, device): # Add device parameter to swtich from T4 to local device\n","    '''function to tokenize the test data input & ground truth and generate predictions'''\n","    predictions = []\n","    references = []\n","\n","    # Preprocess: tokenize input and output\n","    test_dataset = test_dataset.map(preprocess_data)\n","\n","    for example in test_dataset:\n","        #tokenize inputs\n","        # inputs = tokenizer(\n","        #     example[\"input\"], return_tensors=\"pt\", max_length=900, truncation=True, padding=\"max_length\"\n","        # )\n","\n","        # generate tokenized output predictions\n","        input_ids = torch.tensor([example['input_ids']]).to(device)\n","        output_ids = model_saved.generate(input_ids, min_length=200, max_length=400,    #TODO set the model, consider creating function\n","                                              num_beams=5, no_repeat_ngram_size=3)\n","        # Decode to human language\n","        prediction = tokenizer.decode(output_ids[0], skip_special_tokens=True,\n","                                      clean_up_tokenization_spaces=False)\n","        predictions.append(prediction)\n","\n","        #reference text (ground truth)\n","        references.append(example['output'])\n","\n","    return predictions, references"],"metadata":{"id":"0Yv9_wGB5Zue","executionInfo":{"status":"ok","timestamp":1733187723662,"user_tz":480,"elapsed":195,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# debug by not streaming\n","valid_dataset = load_dataset(\"csv\", data_files=valid_filepath)['train']\n","valid_dataset_first3 = valid_dataset.select(range(3))"],"metadata":{"id":"Y5HwEDGB_tyv","executionInfo":{"status":"ok","timestamp":1733187307515,"user_tz":480,"elapsed":492,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["#load rouge metric\n","rouge = load(\"rouge\") #lrouge metric using load function\n","#gpu to local device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","#move model to local\n","model.to(device)\n","\n","#generate predictions and references\n","predictions, references = generate_predictions(valid_dataset, model, tokenizer, device)\n","\n","\n","#calcuating rouge score\n","rouge_results = rouge.compute(predictions=predictions, references=references)\n","print(\"ROUGE Results:\", rouge_results)\n","\n","#BLEU expects references as a list of lists\n","references = [[ref] for ref in references]\n","#calculating BLEU score\n","bleu_score = sacrebleu.corpus_bleu(predictions, references)\n","print(\"BLEU Score:\", bleu_score.score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3lpxAIHp5Zge","executionInfo":{"status":"ok","timestamp":1733187885392,"user_tz":480,"elapsed":159049,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"1641ba69-e428-40e2-b39c-d80fdd512129"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["ROUGE Results: {'rouge1': 0.5354700040430262, 'rouge2': 0.27954138753000163, 'rougeL': 0.33394486831423514, 'rougeLsum': 0.3838069935500195}\n","BLEU Score: 32.48970153123982\n"]}]},{"cell_type":"code","source":["predictions[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14jARI8OG5vM","executionInfo":{"status":"ok","timestamp":1733188045151,"user_tz":480,"elapsed":187,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"ddded31f-7d2a-41c5-a440-76b769081d0c"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"S: The patient reports being referred for a lung adenocarcinoma measuring 28 mm in the right upper lobe. The patient has not been familiar with the procedure. O: During the UVATS procedure, the patient was placed in the left lateral decubitus position under general anesthesia, followed by a 4-cm skin incision for the main port in the sixth intercostal space at the anterior axillary line. A wound retractor was used to allow the insertion of a flexible thoracoscope, endoscopic autosuturing device, and vessel-sealing device. Post-surgery, an incomplete interlobar fissure was found between the upper and midlobes of the lung. A: The primary diagnosis is a recurrent lung tumor with a history of lung cancer. Differential diagnoses could include other causes of lung tumors, but these are less likely given the patient's history and clinical presentation. P: The management plan includes a UVATS operation to resect the tumor. A follow-up appointment will be scheduled to monitor the progress of the procedure and monitor the tumor's progress.\",\n"," \"S: The patient reports noticing thinning eyebrows but has not experienced hair loss elsewhere on the body. The patient has a history of plucking eyebrows with tweezers. No other medical conditions or concerns were reported. O: Physical examination revealed sparse and thin black hairs on the eyebrows, with no hair loss at the frontal hairline or temporal area. Laboratory tests showed alopecia with a white blood cell count of 95% on the thigh, and a hemoglobin level of 11% on the right hemisphere. A: The primary diagnosis is hair loss in the forehead, frontal, and temporal areas. Differential diagnoses could include other causes of hair loss, but these are less likely given the imaging findings. P: The management plan includes a follow-up appointment to monitor the patient's condition and any other concerns. Follow-up appointments will be scheduled to assess the severity of the hair loss. A\",\n"," \"S: The patient, a female with a history of atrial fibrillation treated with oral anticoagulation therapy and topiramate, presented with palpitations that started a few hours ago. She described the palpations as fast and irregular. She was previously treated with amiodarone, which was administered intravenously. O: The 12-lead ECG showed atrial flutter with 240 ms cycle length and a 4:1 atrioventricular response. The patient's previous medications include a recurrent episode of adipose tissue thrombocytopenia, and tachycardia. A: The primary diagnosis is a diastolic heart disease (TBS), characterized by rapid heart beats and irregular heart rhythms. Differential diagnoses could include other causes of heart failure, but these are less likely given the clinical presentation and clinical presentation. P: The management plan includes discontinuation of the medication and reintroduction of the symptom management plan. The plan includes a follow-up appointment to monitor the patient’s heart rate and heart rate, and the patient will be monitored for any changes in heart rate or heart rate. Follow-up appointments will be scheduled to monitor\"]"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":[],"metadata":{"id":"XvG0X1WY5-xU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install evaluate\n","!pip install rouge_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ctlGELQ9oJpw","executionInfo":{"status":"ok","timestamp":1731881738814,"user_tz":480,"elapsed":8431,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"22b2886c-5d18-40bb-b090-8f648a5425ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.3\n","Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.6)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=54bbe02d04e13b3f66e9ec89883130a4ba0d59df1c8545f5d0f4cbb415abaad2\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}]},{"cell_type":"code","source":["import evaluate\n","\n","rouge = evaluate.load(\"rouge\")\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred.predictions[0], eval_pred.label_ids\n","\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    result = rouge.compute(\n","        predictions=decoded_preds,\n","        references=decoded_labels,\n","        use_stemmer=True,\n","        rouge_types=[\n","            'rouge1',\n","            'rouge2',\n","            'rougeL'\n","        ]\n","    )\n","\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","\n","    return {k: round(v, 4) for k, v in result.items()}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["cb6c1a2da064481896ee1a2909ab1241","6c60ad0eef64491c81e1fe7dd47576f9","bf4b9eafd74f4fe09e4a3d0437ed2e55","6d9990d94c0542e081de271476ac1547","efa5d1d73163433390188f586845c9e4","37d8d3f5320c4c73891cac936f99d937","eaf9ffc0f663411e93be34277f8faa81","1489f790949e4033bee93e6801d772d9","20d983edde864d43aeb7e13382242343","dc5b4fa3973842b180ffe5a64efa0470","6f7f947ad7984ccf84dd9a0e680db084"]},"id":"efcfhivqnI-r","executionInfo":{"status":"ok","timestamp":1731881742126,"user_tz":480,"elapsed":3315,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"c50101fc-1924-4f88-f690-5daa23882d4b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb6c1a2da064481896ee1a2909ab1241"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"kNh3h5iIo5Jg"}},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=OUT_DIR,\n","    num_train_epochs=EPOCHS,\n","    # per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    # warmup_steps=500,\n","    # weight_decay=0.01,\n","    logging_dir=OUT_DIR,\n","    # logging_steps=10,\n","    # evaluation_strategy='steps',\n","    # eval_steps=200,\n","    save_strategy='epoch',\n","    save_total_limit=2,\n","    report_to='tensorboard',\n","    # learning_rate=0.0001,\n","    # dataloader_num_workers=4\n",")\n","\n","# training_args = TrainingArguments(\n","#     output_dir=OUT_DIR,\n","#     num_train_epochs=3,\n","#     per_device_train_batch_size=16,\n","#     save_steps=10_000,\n","#     save_total_limit=2,\n","# )\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train,\n","    eval_dataset=tokenized_valid,\n","    # preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n","    compute_metrics=compute_metrics\n",")\n","\n","history = trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":92},"id":"BAOiGeJ1o7WQ","executionInfo":{"status":"ok","timestamp":1731882865915,"user_tz":480,"elapsed":1110217,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"6ed4e8ba-e15e-4839-eef4-b78ae412836d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [26/26 17:29, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Using t5-dialogie-summarization model\n","https://huggingface.co/chanifrusydi/t5-dialogue-summarization?library=transformers"],"metadata":{"id":"lDC0Fq7xAvHI"}},{"cell_type":"code","source":["#pipe = pipeline(\"summarization\", model=\"chanifrusydi/t5-dialogue-summarization\")\n","\n","# Using stock T5 models\n","pipe = pipeline(\"summarization\", model=\"t5-3b\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385,"referenced_widgets":["07a46c2a010f43fa805b303c9171324c","527261a474854cb69542191dedc630be","67ff8e6ef70f4d6196f214fc05e55c8f","a22ce419758d48ba84fac5f9b686940e","5df9eb7c3db24e4fbeb7097c3bcc20c5","1da0a81f23ea4e609e01e0c0d5640929","8488e365c02c477986f0cd425912e556","e28a8264652f45a8a4a9a9981d8ad081","dcf88215093947409800cd93ebb86072","b284a4c0a6184038872ebebed678f9ac","17c8d81f75de48e4ba71e639613f28f2","95c99d73edd64aeba72b9998ec02e5cb","9158c826ea2f43c3a65da1c19d00f5e0","58fef1e77f204c07ad7624e8c9e5da36","59a3f1844f2d4aef85e6baf753ae7d9a","9e6ba2b0bfa84b21aeaeaa9cb3f39093","9f2daf7c4c1f44c3aa79198b26ce54c4","816be08ccae5499f8e682f29bfdf1a30","b010e0da41e44d82af28c30ba3015085","422158eb8f034deea059064f397b906d","3e1e37318055441f92b67f735312dfed","6a185172bf7549a7ab85ceb16372c585"]},"id":"uDSzA78cA3P8","executionInfo":{"status":"error","timestamp":1731538127093,"user_tz":480,"elapsed":185977,"user":{"displayName":"Jonathan Yuechen Luo","userId":"07706929286807043669"}},"outputId":"7189f6be-26d9-48c0-dcc3-dd05a21c1ed7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07a46c2a010f43fa805b303c9171324c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/11.4G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95c99d73edd64aeba72b9998ec02e5cb"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-cee4168fcac0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Using stock T5 models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"summarization\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"t5-3b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0mmodel_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m         framework, model = infer_framework_load_model(\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0mmodel_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3807\u001b[0m                         \u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3808\u001b[0m                     }\n\u001b[0;32m-> 3809\u001b[0;31m                     \u001b[0mresolved_archive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcached_file_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m                     \u001b[0;31m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    863\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mWeakFileLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m         _download_to_tmp_and_move(\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0mincomplete_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".incomplete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0mdestination_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1543\u001b[0m             \u001b[0m_check_disk_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m         http_get(\n\u001b[0m\u001b[1;32m   1546\u001b[0m             \u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                     \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                     \u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m                     \u001b[0mnew_resume_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m                     \u001b[0;31m# Some data has been downloaded from the server so we reset the number of retries.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["summary = pipe(dialogue_sample0)\n","print(summary[0]['summary_text'])"],"metadata":{"id":"lVrjc1J1BJDX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fine tune T5"],"metadata":{"id":"_Ac5rvPRCX-E"}},{"cell_type":"markdown","source":["## TODO: filter **instructions**"],"metadata":{"id":"BmWxiT4FJDBF"}},{"cell_type":"code","source":["t5_model = TFT5ForConditionalGeneration.from_pretrained('t5-large') #also t5-small and t5-large\n","t5_tokenizer = T5Tokenizer.from_pretrained('t5-large')\n","\n","t5_model.summary()"],"metadata":{"id":"NrpQMx-yBohv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set input"],"metadata":{"id":"6ES74GYZBx51"}},{"cell_type":"code","source":["t5_input_text = \"summarize: \" + dialogue_sample0"],"metadata":{"id":"Muv5_zzJB90T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t5_inputs = t5_tokenizer([t5_input_text], return_tensors='tf')"],"metadata":{"id":"ILHUk1voCFwf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Summarize"],"metadata":{"id":"xXrmqZIDCQiG"}},{"cell_type":"code","source":["t5_summary_ids = t5_model.generate(t5_inputs['input_ids'],\n","                                    num_beams=3,\n","                                    no_repeat_ngram_size=10,\n","                                    min_length=100,\n","                                    max_length=500)\n","\n","print([t5_tokenizer.decode(g, skip_special_tokens=True,\n","                           clean_up_tokenization_spaces=False) for g in t5_summary_ids])"],"metadata":{"id":"tTWQFfbeCQIN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mXPElKa7KN5o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the pre-trained T5 model and tokenizer\n","model_name = \"t5-base\"  # also t5-small and t5-large\n","tokenizer = T5Tokenizer.from_pretrained(model_name)  # Load tokenizer\n","model = T5ForConditionalGeneration.from_pretrained(model_name)  # Load model"],"metadata":{"id":"dl2C6mjHCZ1e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ds"],"metadata":{"id":"69fAF8lAtsRP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize_function(examples):\n","    inputs = tokenizer(examples[\"input\"], max_length=512, padding=\"max_length\", truncation=True)\n","    targets = tokenizer(examples[\"output\"], max_length=512, padding=\"max_length\", truncation=True)\n","    inputs[\"labels\"] = targets[\"input_ids\"]\n","    inputs[\"decoder_input_ids\"] = targets[\"input_ids\"]\n","    return inputs\n","\n","tokenized_dataset = ds.map(tokenize_function, batched=True)\n","\n","train_data = tokenized_dataset[\"train\"]\n","val_data = tokenized_dataset[\"validation\"]"],"metadata":{"id":"4tw9LttTvq1c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data"],"metadata":{"id":"VDX56uZzCBiY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    save_steps=10_000,\n","    save_total_limit=2,\n",")\n","\n","# Create a Trainer instance\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=val_data,\n","    tokenizer=tokenizer,\n",")\n","\n","# Start training\n","trainer.train()"],"metadata":{"id":"VRqgY0TP0tPs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"id":"AHr8i2m8eIez"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"sA603zUuVwLz"}}]}